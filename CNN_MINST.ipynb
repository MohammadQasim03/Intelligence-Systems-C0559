{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIGlRbjFSKHHSsaHnLwEmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadQasim03/Intelligence-Systems-C0559/blob/main/CNN_MINST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWmCgy5M-d52",
        "outputId": "9c2dfa08-179b-47f6-a2fd-29670c8df3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 21s 42ms/step - loss: 0.4941 - accuracy: 0.8441 - val_loss: 0.0505 - val_accuracy: 0.9845\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.2053 - accuracy: 0.9391 - val_loss: 0.0380 - val_accuracy: 0.9869\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.1619 - accuracy: 0.9528 - val_loss: 0.0326 - val_accuracy: 0.9897\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.1373 - accuracy: 0.9588 - val_loss: 0.0291 - val_accuracy: 0.9897\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 20s 44ms/step - loss: 0.1224 - accuracy: 0.9639 - val_loss: 0.0329 - val_accuracy: 0.9891\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.1146 - accuracy: 0.9661 - val_loss: 0.0256 - val_accuracy: 0.9909\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.1051 - accuracy: 0.9694 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0984 - accuracy: 0.9711 - val_loss: 0.0276 - val_accuracy: 0.9908\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.0906 - accuracy: 0.9733 - val_loss: 0.0328 - val_accuracy: 0.9903\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.0863 - accuracy: 0.9744 - val_loss: 0.0236 - val_accuracy: 0.9930\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 0.0220 - val_accuracy: 0.9928\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0794 - accuracy: 0.9767 - val_loss: 0.0220 - val_accuracy: 0.9922\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0786 - accuracy: 0.9769 - val_loss: 0.0214 - val_accuracy: 0.9939\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.0757 - accuracy: 0.9780 - val_loss: 0.0190 - val_accuracy: 0.9939\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 0.0734 - accuracy: 0.9781 - val_loss: 0.0216 - val_accuracy: 0.9926\n",
            "Epoch 16/30\n",
            " 35/469 [=>............................] - ETA: 16s - loss: 0.0674 - accuracy: 0.9793"
          ]
        }
      ],
      "source": [
        "import numpy as np  # Importing numpy library for numerical operations\n",
        "import keras  # Importing Keras library for building neural networks\n",
        "from keras.datasets import mnist  # Importing MNIST dataset from Keras\n",
        "from keras.models import Model  # Importing Model class from Keras\n",
        "from keras.layers import Dense, Input  # Importing Dense and Input layers from Keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten  # Importing CNN layers from Keras\n",
        "from keras.preprocessing.image import ImageDataGenerator  # Importing ImageDataGenerator for data augmentation\n",
        "from keras import backend as k  # Importing backend module from Keras for backend-specific operations\n",
        "import matplotlib.pyplot as plt  # Importing matplotlib for plotting\n",
        "from sklearn.metrics import confusion_matrix  # Importing confusion_matrix function from sklearn\n",
        "import seaborn as sns  # Importing seaborn for visualization\n",
        "\n",
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # Loading MNIST dataset into training and testing sets\n",
        "\n",
        "img_rows, img_cols = 28, 28  # Setting image dimensions\n",
        "\n",
        "# Reshape data based on backend (channels-first or channels-last)\n",
        "if k.image_data_format() == 'channels_first':  # Checking if channels are first\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)  # Reshaping training data\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)  # Reshaping testing data\n",
        "    inpx = (1, img_rows, img_cols)  # Input shape for channels-first\n",
        "else:  # If channels are last\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)  # Reshaping training data\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)  # Reshaping testing data\n",
        "    inpx = (img_rows, img_cols, 1)  # Input shape for channels-last\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255  # Normalizing training data\n",
        "x_test = x_test.astype('float32') / 255  # Normalizing testing data\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = keras.utils.to_categorical(y_train)  # One-hot encoding training labels\n",
        "y_test = keras.utils.to_categorical(y_test)  # One-hot encoding testing labels\n",
        "\n",
        "# Define the CNN model\n",
        "inpx = Input(shape=inpx)  # Defining input layer\n",
        "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)  # Adding first convolutional layer\n",
        "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)  # Adding second convolutional layer\n",
        "layer3 = MaxPooling2D(pool_size=(2, 2))(layer2)  # Adding max pooling layer\n",
        "layer4 = Dropout(0.25)(layer3)  # Adding dropout layer\n",
        "layer5 = Flatten()(layer4)  # Flattening the output from convolutional layers\n",
        "layer6 = Dense(128, activation='relu')(layer5)  # Adding dense layer\n",
        "layer7 = Dropout(0.5)(layer6)  # Adding dropout layer\n",
        "layer8 = Dense(10, activation='softmax')(layer7)  # Adding output layer with softmax activation\n",
        "\n",
        "model = Model([inpx], layer8)  # Creating the model\n",
        "model.compile(optimizer='adam',  # Compiling the model with Adam optimizer\n",
        "              loss='categorical_crossentropy',  # Using categorical crossentropy as loss function\n",
        "              metrics=['accuracy'])  # Using accuracy as evaluation metric\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10,  # Augmenting data with rotation\n",
        "                             width_shift_range=0.1,  # Augmenting data with width shift\n",
        "                             height_shift_range=0.1,  # Augmenting data with height shift\n",
        "                             zoom_range=0.1)  # Augmenting data with zoom\n",
        "datagen.fit(x_train)  # Fitting the ImageDataGenerator on training data\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=128),  # Training the model with augmented data\n",
        "                    epochs=30,  # Setting number of epochs\n",
        "                    validation_data=(x_test, y_test))  # Using validation data during training\n",
        "\n",
        "# Plot accuracy versus time\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')  # Plotting training accuracy\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')  # Plotting validation accuracy\n",
        "plt.xlabel('Epoch')  # Setting x-label\n",
        "plt.ylabel('Accuracy')  # Setting y-label\n",
        "plt.legend()  # Adding legend\n",
        "plt.show()  # Displaying the plot\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)  # Evaluating the model on test data\n",
        "print('Loss:', score[0])  # Printing loss\n",
        "print('Accuracy:', score[1])  # Printing accuracy\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = model.predict(x_test)  # Predicting labels for test data\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Getting predicted classes\n",
        "y_true = np.argmax(y_test, axis=1)  # Getting true classes\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)  # Computing confusion matrix\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))  # Setting figure size\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))  # Plotting confusion matrix\n",
        "plt.xlabel('Predicted labels')  # Setting x-label\n",
        "plt.ylabel('True labels')  # Setting y-label\n",
        "plt.title('Confusion Matrix')  # Setting title\n",
        "plt.show()  # Displaying the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g363dtxEXurQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1uCvRvRdXzCw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VPBgrWKQX0oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WWCqJnCAX084"
      }
    }
  ]
}